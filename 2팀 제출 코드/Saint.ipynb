{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1273254b",
   "metadata": {},
   "source": [
    "## Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e93d7591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def embed_data_mask(x_categ, x_cont, cat_mask, con_mask,model,vision_dset=False):\n",
    "    device = x_cont.device\n",
    "    x_categ = x_categ + model.categories_offset.type_as(x_categ)\n",
    "    x_categ_enc = model.embeds(x_categ)\n",
    "    n1,n2 = x_cont.shape\n",
    "    _, n3 = x_categ.shape\n",
    "    if model.cont_embeddings == 'MLP':\n",
    "        x_cont_enc = torch.empty(n1,n2, model.dim)\n",
    "        for i in range(model.num_continuous):\n",
    "            x_cont_enc[:,i,:] = model.simple_MLP[i](x_cont[:,i])\n",
    "    else:\n",
    "        raise Exception('This case should not work!')    \n",
    "\n",
    "\n",
    "    x_cont_enc = x_cont_enc.to(device)\n",
    "    cat_mask_temp = cat_mask + model.cat_mask_offset.type_as(cat_mask)\n",
    "    con_mask_temp = con_mask + model.con_mask_offset.type_as(con_mask)\n",
    "\n",
    "\n",
    "    cat_mask_temp = model.mask_embeds_cat(cat_mask_temp)\n",
    "    con_mask_temp = model.mask_embeds_cont(con_mask_temp)\n",
    "    x_categ_enc[cat_mask == 0] = cat_mask_temp[cat_mask == 0]\n",
    "    x_cont_enc[con_mask == 0] = con_mask_temp[con_mask == 0]\n",
    "\n",
    "    if vision_dset:\n",
    "        \n",
    "        pos = np.tile(np.arange(x_categ.shape[-1]),(x_categ.shape[0],1))\n",
    "        pos =  torch.from_numpy(pos).to(device)\n",
    "        pos_enc =model.pos_encodings(pos)\n",
    "        x_categ_enc+=pos_enc\n",
    "\n",
    "    return x_categ, x_categ_enc, x_cont_enc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mixup_data(x1, x2 , lam=1.0, y= None, use_cuda=True):\n",
    "    '''Returns mixed inputs, pairs of targets'''\n",
    "\n",
    "    batch_size = x1.size()[0]\n",
    "    if use_cuda:\n",
    "        index = torch.randperm(batch_size).cuda()\n",
    "    else:\n",
    "        index = torch.randperm(batch_size)\n",
    "\n",
    "\n",
    "    mixed_x1 = lam * x1 + (1 - lam) * x1[index, :]\n",
    "    mixed_x2 = lam * x2 + (1 - lam) * x2[index, :]\n",
    "    if y is not None:\n",
    "        y_a, y_b = y, y[index]\n",
    "        return mixed_x1, mixed_x2, y_a, y_b\n",
    "    \n",
    "    return mixed_x1, mixed_x2\n",
    "\n",
    "\n",
    "def add_noise(x_categ,x_cont, noise_params = {'noise_type' : ['cutmix'],'lambda' : 0.1}):\n",
    "    lam = noise_params['lambda']\n",
    "    device = x_categ.device\n",
    "    batch_size = x_categ.size()[0]\n",
    "\n",
    "    if 'cutmix' in noise_params['noise_type']:\n",
    "        index = torch.randperm(batch_size)\n",
    "        cat_corr = torch.from_numpy(np.random.choice(2,(x_categ.shape),p=[lam,1-lam])).to(device)\n",
    "        con_corr = torch.from_numpy(np.random.choice(2,(x_cont.shape),p=[lam,1-lam])).to(device)\n",
    "        x1, x2 =  x_categ[index,:], x_cont[index,:]\n",
    "        x_categ_corr, x_cont_corr = x_categ.clone().detach() ,x_cont.clone().detach()\n",
    "        x_categ_corr[cat_corr==0] = x1[cat_corr==0]\n",
    "        x_cont_corr[con_corr==0] = x2[con_corr==0]\n",
    "        return x_categ_corr, x_cont_corr\n",
    "    elif noise_params['noise_type'] == 'missing':\n",
    "        x_categ_mask = np.random.choice(2,(x_categ.shape),p=[lam,1-lam])\n",
    "        x_cont_mask = np.random.choice(2,(x_cont.shape),p=[lam,1-lam])\n",
    "        x_categ_mask = torch.from_numpy(x_categ_mask).to(device)\n",
    "        x_cont_mask = torch.from_numpy(x_cont_mask).to(device)\n",
    "        return torch.mul(x_categ,x_categ_mask), torch.mul(x_cont,x_cont_mask)\n",
    "        \n",
    "    else:\n",
    "        print(\"yet to write this\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ce7e8c",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82e6bf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "def make_default_mask(x):\n",
    "    mask = np.ones_like(x)\n",
    "    mask[:,-1] = 0\n",
    "    return mask\n",
    "\n",
    "def tag_gen(tag,y):\n",
    "    return np.repeat(tag,len(y['data']))\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)  \n",
    "\n",
    "def get_scheduler(args, optimizer):\n",
    "    if args.scheduler == 'cosine':\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, args.epochs)\n",
    "    elif args.scheduler == 'linear':\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                      milestones=[args.epochs // 2.667, args.epochs // 1.6, args.epochs // 1.142], gamma=0.1)\n",
    "    return scheduler\n",
    "\n",
    "def imputations_acc_justy(model,dloader,device):\n",
    "    model.eval()\n",
    "    m = nn.Softmax(dim=1)\n",
    "    y_test = torch.empty(0).to(device)\n",
    "    y_pred = torch.empty(0).to(device)\n",
    "    prob = torch.empty(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dloader, 0):\n",
    "            x_categ, x_cont, cat_mask, con_mask = data[0].to(device), data[1].to(device),data[2].to(device),data[3].to(device)\n",
    "            _ , x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask,model)\n",
    "            reps = model.transformer(x_categ_enc, x_cont_enc)\n",
    "            y_reps = reps[:,model.num_categories-1,:]\n",
    "            y_outs = model.mlpfory(y_reps)\n",
    "            # import ipdb; ipdb.set_trace()   \n",
    "            y_test = torch.cat([y_test,x_categ[:,-1].float()],dim=0)\n",
    "            y_pred = torch.cat([y_pred,torch.argmax(m(y_outs), dim=1).float()],dim=0)\n",
    "            prob = torch.cat([prob,m(y_outs)[:,-1].float()],dim=0)\n",
    "     \n",
    "    correct_results_sum = (y_pred == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]*100\n",
    "    auc = roc_auc_score(y_score=prob.cpu(), y_true=y_test.cpu())\n",
    "    return acc, auc\n",
    "\n",
    "\n",
    "def multiclass_acc_justy(model,dloader,device):\n",
    "    model.eval()\n",
    "    vision_dset = True\n",
    "    m = nn.Softmax(dim=1)\n",
    "    y_test = torch.empty(0).to(device)\n",
    "    y_pred = torch.empty(0).to(device)\n",
    "    prob = torch.empty(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dloader, 0):\n",
    "            x_categ, x_cont, cat_mask, con_mask = data[0].to(device), data[1].to(device),data[2].to(device),data[3].to(device)\n",
    "            _ , x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask,model,vision_dset)\n",
    "            reps = model.transformer(x_categ_enc, x_cont_enc)\n",
    "            y_reps = reps[:,model.num_categories-1,:]\n",
    "            y_outs = model.mlpfory(y_reps)\n",
    "            # import ipdb; ipdb.set_trace()   \n",
    "            y_test = torch.cat([y_test,x_categ[:,-1].float()],dim=0)\n",
    "            y_pred = torch.cat([y_pred,torch.argmax(m(y_outs), dim=1).float()],dim=0)\n",
    "     \n",
    "    correct_results_sum = (y_pred == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]*100\n",
    "    return acc, 0\n",
    "\n",
    "\n",
    "def classification_scores(model, dloader, device, task,vision_dset):\n",
    "    model.eval()\n",
    "    m = nn.Softmax(dim=1)\n",
    "    y_test = torch.empty(0).to(device)\n",
    "    y_pred = torch.empty(0).to(device)\n",
    "    prob = torch.empty(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dloader, 0):\n",
    "            x_categ, x_cont, y_gts, cat_mask, con_mask = data[0].to(device), data[1].to(device),data[2].to(device),data[3].to(device),data[4].to(device)\n",
    "            _ , x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask,model,vision_dset)           \n",
    "            reps = model.transformer(x_categ_enc, x_cont_enc)\n",
    "            y_reps = reps[:,0,:]\n",
    "            y_outs = model.mlpfory(y_reps)\n",
    "            # import ipdb; ipdb.set_trace()   \n",
    "            y_test = torch.cat([y_test,y_gts.squeeze().float()],dim=0)\n",
    "            y_pred = torch.cat([y_pred,torch.argmax(y_outs, dim=1).float()],dim=0)\n",
    "            if task == 'binary':\n",
    "                prob = torch.cat([prob,m(y_outs)[:,-1].float()],dim=0)\n",
    "     \n",
    "    correct_results_sum = (y_pred == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]*100\n",
    "    auc = 0\n",
    "    if task == 'binary':\n",
    "        auc = roc_auc_score(y_score=prob.cpu(), y_true=y_test.cpu())\n",
    "    return acc.cpu().numpy(), auc\n",
    "\n",
    "def mean_sq_error(model, dloader, device, vision_dset):\n",
    "    model.eval()\n",
    "    y_test = torch.empty(0).to(device)\n",
    "    y_pred = torch.empty(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dloader, 0):\n",
    "            x_categ, x_cont, y_gts, cat_mask, con_mask = data[0].to(device), data[1].to(device),data[2].to(device),data[3].to(device),data[4].to(device)\n",
    "            _ , x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask,model,vision_dset)           \n",
    "            reps = model.transformer(x_categ_enc, x_cont_enc)\n",
    "            y_reps = reps[:,0,:]\n",
    "            y_outs = model.mlpfory(y_reps)\n",
    "            y_test = torch.cat([y_test,y_gts.squeeze().float()],dim=0)\n",
    "            y_pred = torch.cat([y_pred,y_outs],dim=0)\n",
    "        # import ipdb; ipdb.set_trace() \n",
    "        rmse = mean_squared_error(y_test.cpu(), y_pred.cpu(), squared=False)\n",
    "        return rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad18c72f",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c943aca",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4c12741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, einsum\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "\n",
    "# helpers\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def default(val, d):\n",
    "    return val if exists(val) else d\n",
    "\n",
    "def ff_encodings(x,B):\n",
    "    x_proj = (2. * np.pi * x.unsqueeze(-1)) @ B.t()\n",
    "    return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "\n",
    "# classes\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(x, **kwargs) + x\n",
    "\n",
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)\n",
    "\n",
    "# attention\n",
    "\n",
    "class GEGLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x, gates = x.chunk(2, dim = -1)\n",
    "        return x * F.gelu(gates)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, mult = 4, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, dim * mult * 2),\n",
    "            GEGLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim * mult, dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        heads = 8,\n",
    "        dim_head = 16,\n",
    "        dropout = 0.\n",
    "    ):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "        self.to_out = nn.Linear(inner_dim, dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.heads\n",
    "        q, k, v = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), (q, k, v))\n",
    "        sim = einsum('b h i d, b h j d -> b h i j', q, k) * self.scale\n",
    "        attn = sim.softmax(dim = -1)\n",
    "        out = einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)', h = h)\n",
    "        return self.to_out(out)\n",
    "\n",
    "\n",
    "class RowColTransformer(nn.Module):\n",
    "    def __init__(self, num_tokens, dim, nfeats, depth, heads, dim_head, attn_dropout, ff_dropout,style='col'):\n",
    "        super().__init__()\n",
    "        self.embeds = nn.Embedding(num_tokens, dim)\n",
    "        self.layers = nn.ModuleList([])\n",
    "        self.mask_embed =  nn.Embedding(nfeats, dim)\n",
    "        self.style = style\n",
    "        for _ in range(depth):\n",
    "            if self.style == 'colrow':\n",
    "                self.layers.append(nn.ModuleList([\n",
    "                    PreNorm(dim, Residual(Attention(dim, heads = heads, dim_head = dim_head, dropout = attn_dropout))),\n",
    "                    PreNorm(dim, Residual(FeedForward(dim, dropout = ff_dropout))),\n",
    "                    PreNorm(dim*nfeats, Residual(Attention(dim*nfeats, heads = heads, dim_head = 64, dropout = attn_dropout))),\n",
    "                    PreNorm(dim*nfeats, Residual(FeedForward(dim*nfeats, dropout = ff_dropout))),\n",
    "                ]))\n",
    "            else:\n",
    "                self.layers.append(nn.ModuleList([\n",
    "                    PreNorm(dim*nfeats, Residual(Attention(dim*nfeats, heads = heads, dim_head = 64, dropout = attn_dropout))),\n",
    "                    PreNorm(dim*nfeats, Residual(FeedForward(dim*nfeats, dropout = ff_dropout))),\n",
    "                ]))\n",
    "\n",
    "    def forward(self, x, x_cont=None, mask = None):\n",
    "        if x_cont is not None:\n",
    "            x = torch.cat((x,x_cont),dim=1)\n",
    "        _, n, _ = x.shape\n",
    "        if self.style == 'colrow':\n",
    "            for attn1, ff1, attn2, ff2 in self.layers: \n",
    "                x = attn1(x)\n",
    "                x = ff1(x)\n",
    "                x = rearrange(x, 'b n d -> 1 b (n d)')\n",
    "                x = attn2(x)\n",
    "                x = ff2(x)\n",
    "                x = rearrange(x, '1 b (n d) -> b n d', n = n)\n",
    "        else:\n",
    "             for attn1, ff1 in self.layers:\n",
    "                x = rearrange(x, 'b n d -> 1 b (n d)')\n",
    "                x = attn1(x)\n",
    "                x = ff1(x)\n",
    "                x = rearrange(x, '1 b (n d) -> b n d', n = n)\n",
    "        return x\n",
    "\n",
    "\n",
    "# transformer\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_tokens, dim, depth, heads, dim_head, attn_dropout, ff_dropout):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "\n",
    "\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                PreNorm(dim, Residual(Attention(dim, heads = heads, dim_head = dim_head, dropout = attn_dropout))),\n",
    "                PreNorm(dim, Residual(FeedForward(dim, dropout = ff_dropout))),\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x, x_cont=None):\n",
    "        if x_cont is not None:\n",
    "            x = torch.cat((x,x_cont),dim=1)\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x)\n",
    "            x = ff(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "#mlp\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, dims, act = None):\n",
    "        super().__init__()\n",
    "        dims_pairs = list(zip(dims[:-1], dims[1:]))\n",
    "        layers = []\n",
    "        for ind, (dim_in, dim_out) in enumerate(dims_pairs):\n",
    "            is_last = ind >= (len(dims) - 1)\n",
    "            linear = nn.Linear(dim_in, dim_out)\n",
    "            layers.append(linear)\n",
    "\n",
    "            if is_last:\n",
    "                continue\n",
    "            if act is not None:\n",
    "                layers.append(act)\n",
    "\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class simple_MLP(nn.Module):\n",
    "    def __init__(self,dims):\n",
    "        super(simple_MLP, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(dims[0], dims[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(dims[1], dims[2])\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if len(x.shape)==1:\n",
    "            x = x.view(x.size(0), -1)\n",
    "        x = self.layers(x)\n",
    "        return x\n",
    "\n",
    "# main class\n",
    "\n",
    "class TabAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        categories,\n",
    "        num_continuous,\n",
    "        dim,\n",
    "        depth,\n",
    "        heads,\n",
    "        dim_head = 16,\n",
    "        dim_out = 1,\n",
    "        mlp_hidden_mults = (4, 2),\n",
    "        mlp_act = None,\n",
    "        num_special_tokens = 1,\n",
    "        continuous_mean_std = None,\n",
    "        attn_dropout = 0.,\n",
    "        ff_dropout = 0.,\n",
    "        lastmlp_dropout = 0.,\n",
    "        cont_embeddings = 'MLP',\n",
    "        scalingfactor = 10,\n",
    "        attentiontype = 'col'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert all(map(lambda n: n > 0, categories)), 'number of each category must be positive'\n",
    "\n",
    "        # categories related calculations\n",
    "        self.num_categories = len(categories)\n",
    "        self.num_unique_categories = sum(categories)\n",
    "\n",
    "        # create category embeddings table\n",
    "\n",
    "        self.num_special_tokens = num_special_tokens\n",
    "        self.total_tokens = self.num_unique_categories + num_special_tokens\n",
    "\n",
    "        # for automatically offsetting unique category ids to the correct position in the categories embedding table\n",
    "        categories_offset = F.pad(torch.tensor(list(categories)), (1, 0), value = num_special_tokens)\n",
    "        categories_offset = categories_offset.cumsum(dim = -1)[:-1]\n",
    "        \n",
    "        self.register_buffer('categories_offset', categories_offset)\n",
    "\n",
    "\n",
    "        self.norm = nn.LayerNorm(num_continuous)\n",
    "        self.num_continuous = num_continuous\n",
    "        self.dim = dim\n",
    "        self.cont_embeddings = cont_embeddings\n",
    "        self.attentiontype = attentiontype\n",
    "\n",
    "        if self.cont_embeddings == 'MLP':\n",
    "            self.simple_MLP = nn.ModuleList([simple_MLP([1,100,self.dim]) for _ in range(self.num_continuous)])\n",
    "            input_size = (dim * self.num_categories)  + (dim * num_continuous)\n",
    "            nfeats = self.num_categories + num_continuous\n",
    "        else:\n",
    "            print('Continous features are not passed through attention')\n",
    "            input_size = (dim * self.num_categories) + num_continuous\n",
    "            nfeats = self.num_categories \n",
    "\n",
    "        # transformer\n",
    "        if attentiontype == 'col':\n",
    "            self.transformer = Transformer(\n",
    "                num_tokens = self.total_tokens,\n",
    "                dim = dim,\n",
    "                depth = depth,\n",
    "                heads = heads,\n",
    "                dim_head = dim_head,\n",
    "                attn_dropout = attn_dropout,\n",
    "                ff_dropout = ff_dropout\n",
    "            )\n",
    "        elif attentiontype in ['row','colrow'] :\n",
    "            self.transformer = RowColTransformer(\n",
    "                num_tokens = self.total_tokens,\n",
    "                dim = dim,\n",
    "                nfeats= nfeats,\n",
    "                depth = depth,\n",
    "                heads = heads,\n",
    "                dim_head = dim_head,\n",
    "                attn_dropout = attn_dropout,\n",
    "                ff_dropout = ff_dropout,\n",
    "                style = attentiontype\n",
    "            )\n",
    "\n",
    "        l = input_size // 8\n",
    "        hidden_dimensions = list(map(lambda t: l * t, mlp_hidden_mults))\n",
    "        all_dimensions = [input_size, *hidden_dimensions, dim_out]\n",
    "        \n",
    "        self.mlp = MLP(all_dimensions, act = mlp_act)\n",
    "        self.embeds = nn.Embedding(self.total_tokens, self.dim) #.to(device)\n",
    "\n",
    "        cat_mask_offset = F.pad(torch.Tensor(self.num_categories).fill_(2).type(torch.int8), (1, 0), value = 0) \n",
    "        cat_mask_offset = cat_mask_offset.cumsum(dim = -1)[:-1]\n",
    "\n",
    "        con_mask_offset = F.pad(torch.Tensor(self.num_continuous).fill_(2).type(torch.int8), (1, 0), value = 0) \n",
    "        con_mask_offset = con_mask_offset.cumsum(dim = -1)[:-1]\n",
    "\n",
    "        self.register_buffer('cat_mask_offset', cat_mask_offset)\n",
    "        self.register_buffer('con_mask_offset', con_mask_offset)\n",
    "\n",
    "        self.mask_embeds_cat = nn.Embedding(self.num_categories*2, self.dim)\n",
    "        self.mask_embeds_cont = nn.Embedding(self.num_continuous*2, self.dim)\n",
    "\n",
    "    def forward(self, x_categ, x_cont,x_categ_enc,x_cont_enc):\n",
    "        device = x_categ.device\n",
    "        if self.attentiontype == 'justmlp':\n",
    "            if x_categ.shape[-1] > 0:\n",
    "                flat_categ = x_categ.flatten(1).to(device)\n",
    "                x = torch.cat((flat_categ, x_cont.flatten(1).to(device)), dim = -1)\n",
    "            else:\n",
    "                x = x_cont.clone()\n",
    "        else:\n",
    "            if self.cont_embeddings == 'MLP':\n",
    "                x = self.transformer(x_categ_enc,x_cont_enc.to(device))\n",
    "            else:\n",
    "                if x_categ.shape[-1] <= 0:\n",
    "                    x = x_cont.clone()\n",
    "                else: \n",
    "                    flat_categ = self.transformer(x_categ_enc).flatten(1)\n",
    "                    x = torch.cat((flat_categ, x_cont), dim = -1)                    \n",
    "        flat_x = x.flatten(1)\n",
    "        return self.mlp(flat_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2042b7",
   "metadata": {},
   "source": [
    "### pretrainmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41228d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sep_MLP(nn.Module):\n",
    "    def __init__(self,dim,len_feats,categories):\n",
    "        super(sep_MLP, self).__init__()\n",
    "        self.len_feats = len_feats\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for i in range(len_feats):\n",
    "            self.layers.append(simple_MLP([dim,5*dim, categories[i]]))\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = list([])\n",
    "        for i in range(self.len_feats):\n",
    "            x_i = x[:,i,:]\n",
    "            pred = self.layers[i](x_i)\n",
    "            y_pred.append(pred)\n",
    "        return y_pred\n",
    "\n",
    "class SAINT(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        categories,\n",
    "        num_continuous,\n",
    "        dim,\n",
    "        depth,\n",
    "        heads,\n",
    "        dim_head = 16,\n",
    "        dim_out = 1,\n",
    "        mlp_hidden_mults = (4, 2),\n",
    "        mlp_act = None,\n",
    "        num_special_tokens = 0,\n",
    "        attn_dropout = 0.,\n",
    "        ff_dropout = 0.,\n",
    "        cont_embeddings = 'MLP',\n",
    "        scalingfactor = 10,\n",
    "        attentiontype = 'col',\n",
    "        final_mlp_style = 'common',\n",
    "        y_dim = 2\n",
    "        ):\n",
    "        super().__init__()\n",
    "        assert all(map(lambda n: n > 0, categories)), 'number of each category must be positive'\n",
    "\n",
    "        # categories related calculations\n",
    "\n",
    "        self.num_categories = len(categories)\n",
    "        self.num_unique_categories = sum(categories)\n",
    "\n",
    "        # create category embeddings table\n",
    "\n",
    "        self.num_special_tokens = num_special_tokens\n",
    "        self.total_tokens = self.num_unique_categories + num_special_tokens\n",
    "\n",
    "        # for automatically offsetting unique category ids to the correct position in the categories embedding table\n",
    "\n",
    "        categories_offset = F.pad(torch.tensor(list(categories)), (1, 0), value = num_special_tokens)\n",
    "        categories_offset = categories_offset.cumsum(dim = -1)[:-1]\n",
    "        \n",
    "        self.register_buffer('categories_offset', categories_offset)\n",
    "\n",
    "\n",
    "        self.norm = nn.LayerNorm(num_continuous)\n",
    "        self.num_continuous = num_continuous\n",
    "        self.dim = dim\n",
    "        self.cont_embeddings = cont_embeddings\n",
    "        self.attentiontype = attentiontype\n",
    "        self.final_mlp_style = final_mlp_style\n",
    "\n",
    "        if self.cont_embeddings == 'MLP':\n",
    "            self.simple_MLP = nn.ModuleList([simple_MLP([1,100,self.dim]) for _ in range(self.num_continuous)])\n",
    "            input_size = (dim * self.num_categories)  + (dim * num_continuous)\n",
    "            nfeats = self.num_categories + num_continuous\n",
    "        elif self.cont_embeddings == 'pos_singleMLP':\n",
    "            self.simple_MLP = nn.ModuleList([simple_MLP([1,100,self.dim]) for _ in range(1)])\n",
    "            input_size = (dim * self.num_categories)  + (dim * num_continuous)\n",
    "            nfeats = self.num_categories + num_continuous\n",
    "        else:\n",
    "            print('Continous features are not passed through attention')\n",
    "            input_size = (dim * self.num_categories) + num_continuous\n",
    "            nfeats = self.num_categories \n",
    "\n",
    "        # transformer\n",
    "        if attentiontype == 'col':\n",
    "            self.transformer = Transformer(\n",
    "                num_tokens = self.total_tokens,\n",
    "                dim = dim,\n",
    "                depth = depth,\n",
    "                heads = heads,\n",
    "                dim_head = dim_head,\n",
    "                attn_dropout = attn_dropout,\n",
    "                ff_dropout = ff_dropout\n",
    "            )\n",
    "        elif attentiontype in ['row','colrow'] :\n",
    "            self.transformer = RowColTransformer(\n",
    "                num_tokens = self.total_tokens,\n",
    "                dim = dim,\n",
    "                nfeats= nfeats,\n",
    "                depth = depth,\n",
    "                heads = heads,\n",
    "                dim_head = dim_head,\n",
    "                attn_dropout = attn_dropout,\n",
    "                ff_dropout = ff_dropout,\n",
    "                style = attentiontype\n",
    "            )\n",
    "\n",
    "        l = input_size // 8\n",
    "        hidden_dimensions = list(map(lambda t: l * t, mlp_hidden_mults))\n",
    "        all_dimensions = [input_size, *hidden_dimensions, dim_out]\n",
    "        \n",
    "        self.mlp = MLP(all_dimensions, act = mlp_act)\n",
    "        self.embeds = nn.Embedding(self.total_tokens, self.dim) #.to(device)\n",
    "\n",
    "        cat_mask_offset = F.pad(torch.Tensor(self.num_categories).fill_(2).type(torch.int8), (1, 0), value = 0) \n",
    "        cat_mask_offset = cat_mask_offset.cumsum(dim = -1)[:-1]\n",
    "\n",
    "        con_mask_offset = F.pad(torch.Tensor(self.num_continuous).fill_(2).type(torch.int8), (1, 0), value = 0) \n",
    "        con_mask_offset = con_mask_offset.cumsum(dim = -1)[:-1]\n",
    "\n",
    "        self.register_buffer('cat_mask_offset', cat_mask_offset)\n",
    "        self.register_buffer('con_mask_offset', con_mask_offset)\n",
    "\n",
    "        self.mask_embeds_cat = nn.Embedding(self.num_categories*2, self.dim)\n",
    "        self.mask_embeds_cont = nn.Embedding(self.num_continuous*2, self.dim)\n",
    "        self.single_mask = nn.Embedding(2, self.dim)\n",
    "        self.pos_encodings = nn.Embedding(self.num_categories+ self.num_continuous, self.dim)\n",
    "        \n",
    "        if self.final_mlp_style == 'common':\n",
    "            self.mlp1 = simple_MLP([dim,(self.total_tokens)*2, self.total_tokens])\n",
    "            self.mlp2 = simple_MLP([dim ,(self.num_continuous), 1])\n",
    "\n",
    "        else:\n",
    "            self.mlp1 = sep_MLP(dim,self.num_categories,categories)\n",
    "            self.mlp2 = sep_MLP(dim,self.num_continuous,np.ones(self.num_continuous).astype(int))\n",
    "\n",
    "\n",
    "        self.mlpfory = simple_MLP([dim ,1000, y_dim])\n",
    "        self.pt_mlp = simple_MLP([dim*(self.num_continuous+self.num_categories) ,6*dim*(self.num_continuous+self.num_categories)//5, dim*(self.num_continuous+self.num_categories)//2])\n",
    "        self.pt_mlp2 = simple_MLP([dim*(self.num_continuous+self.num_categories) ,6*dim*(self.num_continuous+self.num_categories)//5, dim*(self.num_continuous+self.num_categories)//2])\n",
    "\n",
    "        \n",
    "    def forward(self, x_categ, x_cont):\n",
    "        \n",
    "        x = self.transformer(x_categ, x_cont)\n",
    "        cat_outs = self.mlp1(x[:,:self.num_categories,:])\n",
    "        con_outs = self.mlp2(x[:,self.num_categories:,:])\n",
    "        return cat_outs, con_outs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404d7e45",
   "metadata": {},
   "source": [
    "### pretrainmodel_vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed24a355",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sep_MLP(nn.Module):\n",
    "    def __init__(self,dim,len_feats,categories):\n",
    "        super(sep_MLP, self).__init__()\n",
    "        self.len_feats = len_feats\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for i in range(len_feats):\n",
    "            self.layers.append(simple_MLP([dim,5*dim, categories[i]]))\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y_pred = list([])\n",
    "        for i in range(self.len_feats):\n",
    "            x_i = x[:,i,:]\n",
    "            pred = self.layers[i](x_i)\n",
    "            y_pred.append(pred)\n",
    "        return y_pred\n",
    "\n",
    "class SAINT_vision(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        categories,\n",
    "        num_continuous,\n",
    "        dim,\n",
    "        depth,\n",
    "        heads,\n",
    "        dim_head = 16,\n",
    "        dim_out = 1,\n",
    "        mlp_hidden_mults = (4, 2),\n",
    "        mlp_act = None,\n",
    "        num_special_tokens = 0,\n",
    "        continuous_mean_std = None,\n",
    "        attn_dropout = 0.,\n",
    "        ff_dropout = 0.,\n",
    "        cont_embeddings = 'MLP',\n",
    "        scalingfactor = 10,\n",
    "        attentiontype = 'col',\n",
    "        final_mlp_style = 'common',\n",
    "        y_dim = 2\n",
    "        ):\n",
    "        super().__init__()\n",
    "        assert all(map(lambda n: n > 0, categories)), 'number of each category must be positive'\n",
    "\n",
    "        # categories related calculations\n",
    "\n",
    "        self.num_categories = len(categories)\n",
    "        self.num_unique_categories = sum(categories)\n",
    "\n",
    "        # create category embeddings table\n",
    "\n",
    "        self.num_special_tokens = num_special_tokens\n",
    "        self.total_tokens = categories[-1] + 256\n",
    "\n",
    "        # for automatically offsetting unique category ids to the correct position in the categories embedding table\n",
    "\n",
    "        categories_offset = torch.tensor(np.append(np.repeat(0, self.num_categories-1),[256]))\n",
    "        self.register_buffer('categories_offset', categories_offset)\n",
    "\n",
    "\n",
    "        self.norm = nn.LayerNorm(num_continuous)\n",
    "        self.num_continuous = num_continuous\n",
    "        self.dim = dim\n",
    "        self.cont_embeddings = cont_embeddings\n",
    "        self.attentiontype = attentiontype\n",
    "        self.final_mlp_style = final_mlp_style\n",
    "\n",
    "        if self.cont_embeddings == 'MLP':\n",
    "            self.simple_MLP = nn.ModuleList([simple_MLP([1,100,self.dim]) for _ in range(self.num_continuous)])\n",
    "            input_size = (dim * self.num_categories)  + (dim * num_continuous)\n",
    "            nfeats = self.num_categories + num_continuous\n",
    "        else:\n",
    "            print('Continous features are not passed through attention')\n",
    "            input_size = (dim * self.num_categories) + num_continuous\n",
    "            nfeats = self.num_categories \n",
    "\n",
    "        # transformer\n",
    "        if attentiontype == 'col':\n",
    "            self.transformer = Transformer(\n",
    "                num_tokens = self.total_tokens,\n",
    "                dim = dim,\n",
    "                depth = depth,\n",
    "                heads = heads,\n",
    "                dim_head = dim_head,\n",
    "                attn_dropout = attn_dropout,\n",
    "                ff_dropout = ff_dropout\n",
    "            )\n",
    "        elif attentiontype in ['row','colrow'] :\n",
    "            self.transformer = RowColTransformer(\n",
    "                num_tokens = self.total_tokens,\n",
    "                dim = dim,\n",
    "                nfeats= nfeats,\n",
    "                depth = depth,\n",
    "                heads = heads,\n",
    "                dim_head = dim_head,\n",
    "                attn_dropout = attn_dropout,\n",
    "                ff_dropout = ff_dropout,\n",
    "                style = attentiontype\n",
    "            )\n",
    "\n",
    "        l = input_size // 8\n",
    "        hidden_dimensions = list(map(lambda t: l * t, mlp_hidden_mults))\n",
    "        all_dimensions = [input_size, *hidden_dimensions, dim_out]\n",
    "        \n",
    "        self.mlp = MLP(all_dimensions, act = mlp_act)\n",
    "        self.embeds = nn.Embedding(self.total_tokens, self.dim) \n",
    "\n",
    "        cat_mask_offset = torch.tensor(np.append(np.repeat(0, self.num_categories-1),[2]))\n",
    "        con_mask_offset = torch.empty(0)\n",
    "\n",
    "        self.register_buffer('cat_mask_offset', cat_mask_offset)\n",
    "        self.register_buffer('con_mask_offset', con_mask_offset)\n",
    "\n",
    "        self.mask_embeds_cat = nn.Embedding(4, self.dim)\n",
    "        self.mask_embeds_cont = nn.Embedding(4, self.dim)\n",
    "        self.pos_encodings = nn.Embedding(self.num_categories, self.dim)\n",
    "        if self.final_mlp_style == 'common':\n",
    "            self.mlp1 = simple_MLP([dim,(self.total_tokens)*2, self.total_tokens])\n",
    "            self.mlp2 = simple_MLP([dim ,(self.num_continuous), 1])\n",
    "\n",
    "        else:\n",
    "            self.mlp1 = sep_MLP(dim,self.num_categories,categories)\n",
    "            self.mlp2 = sep_MLP(dim,self.num_continuous,np.ones(self.num_continuous).astype(int))\n",
    "\n",
    "\n",
    "        self.mlpfory = simple_MLP([dim ,100, y_dim])\n",
    "\n",
    "        \n",
    "    def forward(self, x_categ, x_cont):\n",
    "        x = self.transformer(x_categ, x_cont)\n",
    "        y_reps = x[:,self.num_categories-1,:]\n",
    "        y_outs = self.mlpfory(y_reps)\n",
    "        return y_outs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61648b19",
   "metadata": {},
   "source": [
    "## data_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6469e9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "def simple_lapsed_time(text, lapsed):\n",
    "    hours, rem = divmod(lapsed, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print(text+\": {:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "\n",
    "\n",
    "def task_dset_ids(task):\n",
    "    dataset_ids = {\n",
    "        'binary': [1487,44,1590,42178,1111,31,42733,1494,1017,4134],\n",
    "        'multiclass': [188, 1596, 4541, 40664, 40685, 40687, 40975, 41166, 41169, 42734],\n",
    "        'regression':[541, 42726, 42727, 422, 42571, 42705, 42728, 42563, 42724, 42729]\n",
    "    }\n",
    "\n",
    "    return dataset_ids[task]\n",
    "\n",
    "def concat_data(X,y):\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "    return pd.concat([pd.DataFrame(X['data']), pd.DataFrame(y['data'][:,0].tolist(),columns=['target'])], axis=1)\n",
    "\n",
    "\n",
    "def data_split(X,y,nan_mask,indices):\n",
    "    x_d = {\n",
    "        'data': X.values[indices],\n",
    "        'mask': nan_mask.values[indices]\n",
    "    }\n",
    "    \n",
    "    if x_d['data'].shape != x_d['mask'].shape:\n",
    "        raise'Shape of data not same as that of nan mask!'\n",
    "        \n",
    "    y_d = {\n",
    "        'data': y[indices].reshape(-1, 1)\n",
    "    } \n",
    "    return x_d, y_d\n",
    "\n",
    "\n",
    "def data_prep(dataset, target_name, seed, task, datasplit=[.65, .15, .2]):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    unused_feat = ['ID_code']\n",
    "    features = [ col for col in dataset.columns if col not in unused_feat+[target_name]] \n",
    "    X = dataset[features]\n",
    "    y = dataset[target_name]\n",
    "    \n",
    "    \n",
    "    categorical_columns = []\n",
    "    cont_columns = list(set(X.columns.tolist()) - set(categorical_columns))\n",
    "\n",
    "    cat_idxs = []\n",
    "    con_idxs = list(set(range(len(X.columns))) - set(cat_idxs))\n",
    "\n",
    "    for col in categorical_columns:\n",
    "        X[col] = X[col].astype(\"object\")\n",
    "\n",
    "    X[\"Set\"] = np.random.choice([\"train\", \"valid\", \"test\"], p = datasplit, size=(X.shape[0],))\n",
    "\n",
    "    train_indices = X[X.Set==\"train\"].index\n",
    "    valid_indices = X[X.Set==\"valid\"].index\n",
    "    test_indices = X[X.Set==\"test\"].index\n",
    "\n",
    "    X = X.drop(columns=['Set'])\n",
    "    temp = X.fillna(\"MissingValue\")\n",
    "    nan_mask = temp.ne(\"MissingValue\").astype(int)\n",
    "    \n",
    "    cat_dims = []\n",
    "    for col in categorical_columns:\n",
    "    #     X[col] = X[col].cat.add_categories(\"MissingValue\")\n",
    "        X[col] = X[col].fillna(\"MissingValue\")\n",
    "        l_enc = LabelEncoder() \n",
    "        X[col] = l_enc.fit_transform(X[col].values)\n",
    "        cat_dims.append(len(l_enc.classes_))\n",
    "    for col in cont_columns:\n",
    "    #     X[col].fillna(\"MissingValue\",inplace=True)\n",
    "        X.fillna(X.loc[train_indices, col].mean(), inplace=True)\n",
    "    y = y.values\n",
    "    if task != 'regression':\n",
    "        l_enc = LabelEncoder() \n",
    "        y = l_enc.fit_transform(y)\n",
    "    X_train, y_train = data_split(X,y,nan_mask,train_indices)\n",
    "    X_valid, y_valid = data_split(X,y,nan_mask,valid_indices)\n",
    "    X_test, y_test = data_split(X,y,nan_mask,test_indices)\n",
    "\n",
    "    train_mean, train_std = np.array(X_train['data'][:,con_idxs],dtype=np.float32).mean(0), np.array(X_train['data'][:,con_idxs],dtype=np.float32).std(0)\n",
    "    train_std = np.where(train_std < 1e-6, 1e-6, train_std)\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "    return cat_dims, cat_idxs, con_idxs, X_train, y_train, X_valid, y_valid, X_test, y_test, train_mean, train_std\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DataSetCatCon(Dataset):\n",
    "    def __init__(self, X, Y, cat_cols,task='clf',continuous_mean_std=None):\n",
    "        \n",
    "        cat_cols = list(cat_cols)\n",
    "        X_mask =  X['mask'].copy()\n",
    "        X = X['data'].copy()\n",
    "        con_cols = list(set(np.arange(X.shape[1])) - set(cat_cols))\n",
    "        self.X1 = X[:,cat_cols].copy().astype(np.int64) #categorical columns\n",
    "        self.X2 = X[:,con_cols].copy().astype(np.float32) #numerical columns\n",
    "        self.X1_mask = X_mask[:,cat_cols].copy().astype(np.int64) #categorical columns\n",
    "        self.X2_mask = X_mask[:,con_cols].copy().astype(np.int64) #numerical columns\n",
    "        if task == 'clf':\n",
    "            self.y = Y['data']#.astype(np.float32)\n",
    "        else:\n",
    "            self.y = Y['data'].astype(np.float32)\n",
    "        self.cls = np.zeros_like(self.y,dtype=int)\n",
    "        self.cls_mask = np.ones_like(self.y,dtype=int)\n",
    "        if continuous_mean_std is not None:\n",
    "            mean, std = continuous_mean_std\n",
    "            self.X2 = (self.X2 - mean) / std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # X1 has categorical data, X2 has continuous\n",
    "        return np.concatenate((self.cls[idx], self.X1[idx])), self.X2[idx],self.y[idx], np.concatenate((self.cls_mask[idx], self.X1_mask[idx])), self.X2_mask[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b794151",
   "metadata": {},
   "source": [
    "## Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e51c2526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "def SAINT_pretrain(model,cat_idxs,X_train,y_train,continuous_mean_std,opt,device):\n",
    "    train_ds = DataSetCatCon(X_train, y_train, cat_idxs,opt.dtask, continuous_mean_std)\n",
    "    trainloader = DataLoader(train_ds, batch_size=opt.batchsize, shuffle=True,num_workers=0)\n",
    "    vision_dset = opt.vision_dset\n",
    "    optimizer = optim.AdamW(model.parameters(),lr=0.0001)\n",
    "    pt_aug_dict = {\n",
    "        'noise_type' : opt.pt_aug,\n",
    "        'lambda' : opt.pt_aug_lam\n",
    "    }\n",
    "    criterion1 = nn.CrossEntropyLoss()\n",
    "    criterion2 = nn.MSELoss()\n",
    "    print(\"Pretraining begins!\")\n",
    "    for epoch in range(opt.pretrain_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            optimizer.zero_grad()\n",
    "            x_categ, x_cont, _ ,cat_mask, con_mask = data[0].to(device), data[1].to(device),data[2].to(device),data[3].to(device),data[4].to(device)\n",
    "            \n",
    "            # embed_data_mask function is used to embed both categorical and continuous data.\n",
    "            if 'cutmix' in opt.pt_aug:\n",
    "                from augmentations import add_noise\n",
    "                x_categ_corr, x_cont_corr = add_noise(x_categ,x_cont, noise_params = pt_aug_dict)\n",
    "                _ , x_categ_enc_2, x_cont_enc_2 = embed_data_mask(x_categ_corr, x_cont_corr, cat_mask, con_mask,model,vision_dset)\n",
    "            else:\n",
    "                _ , x_categ_enc_2, x_cont_enc_2 = embed_data_mask(x_categ, x_cont, cat_mask, con_mask,model,vision_dset)\n",
    "            _ , x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask,model,vision_dset)\n",
    "            \n",
    "            if 'mixup' in opt.pt_aug:\n",
    "                from augmentations import mixup_data\n",
    "                x_categ_enc_2, x_cont_enc_2 = mixup_data(x_categ_enc_2, x_cont_enc_2 , lam=opt.mixup_lam)\n",
    "            loss = 0\n",
    "            if 'contrastive' in opt.pt_tasks:\n",
    "                aug_features_1  = model.transformer(x_categ_enc, x_cont_enc)\n",
    "                aug_features_2 = model.transformer(x_categ_enc_2, x_cont_enc_2)\n",
    "                aug_features_1 = (aug_features_1 / aug_features_1.norm(dim=-1, keepdim=True)).flatten(1,2)\n",
    "                aug_features_2 = (aug_features_2 / aug_features_2.norm(dim=-1, keepdim=True)).flatten(1,2)\n",
    "                if opt.pt_projhead_style == 'diff':\n",
    "                    aug_features_1 = model.pt_mlp(aug_features_1)\n",
    "                    aug_features_2 = model.pt_mlp2(aug_features_2)\n",
    "                elif opt.pt_projhead_style == 'same':\n",
    "                    aug_features_1 = model.pt_mlp(aug_features_1)\n",
    "                    aug_features_2 = model.pt_mlp(aug_features_2)\n",
    "                else:\n",
    "                    print('Not using projection head')\n",
    "                logits_per_aug1 = aug_features_1 @ aug_features_2.t()/opt.nce_temp\n",
    "                logits_per_aug2 =  aug_features_2 @ aug_features_1.t()/opt.nce_temp\n",
    "                targets = torch.arange(logits_per_aug1.size(0)).to(logits_per_aug1.device)\n",
    "                loss_1 = criterion1(logits_per_aug1, targets)\n",
    "                loss_2 = criterion1(logits_per_aug2, targets)\n",
    "                loss   = opt.lam0*(loss_1 + loss_2)/2\n",
    "            elif 'contrastive_sim' in opt.pt_tasks:\n",
    "                aug_features_1  = model.transformer(x_categ_enc, x_cont_enc)\n",
    "                aug_features_2 = model.transformer(x_categ_enc_2, x_cont_enc_2)\n",
    "                aug_features_1 = (aug_features_1 / aug_features_1.norm(dim=-1, keepdim=True)).flatten(1,2)\n",
    "                aug_features_2 = (aug_features_2 / aug_features_2.norm(dim=-1, keepdim=True)).flatten(1,2)\n",
    "                aug_features_1 = model.pt_mlp(aug_features_1)\n",
    "                aug_features_2 = model.pt_mlp2(aug_features_2)\n",
    "                c1 = aug_features_1 @ aug_features_2.t()\n",
    "                loss+= opt.lam1*torch.diagonal(-1*c1).add_(1).pow_(2).sum()\n",
    "            if 'denoising' in opt.pt_tasks:\n",
    "                cat_outs, con_outs = model(x_categ_enc_2, x_cont_enc_2)\n",
    "                # if con_outs.shape(-1) != 0:\n",
    "                # import ipdb; ipdb.set_trace()\n",
    "                if len(con_outs) > 0:\n",
    "                    con_outs =  torch.cat(con_outs,dim=1)\n",
    "                    l2 = criterion2(con_outs, x_cont)\n",
    "                else:\n",
    "                    l2 = 0\n",
    "                l1 = 0\n",
    "                # import ipdb; ipdb.set_trace()\n",
    "                n_cat = x_categ.shape[-1]\n",
    "                for j in range(1,n_cat):\n",
    "                    l1+= criterion1(cat_outs[j],x_categ[:,j])\n",
    "                loss += opt.lam2*l1 + opt.lam3*l2    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch: {epoch}, Running Loss: {running_loss}')\n",
    "\n",
    "    print('END OF PRETRAINING!')\n",
    "    return model\n",
    "        # if opt.active_log:\n",
    "        #     wandb.log({'pt_epoch': epoch ,'pretrain_epoch_loss': running_loss\n",
    "        #     })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2395c63",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da044c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import argparse\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3f22530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--final_mlp_style'], dest='final_mlp_style', nargs=None, const=None, default='sep', type=<class 'str'>, choices=['common', 'sep'], required=False, help=None, metavar=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--dset_id', required=True, type=int)\n",
    "parser.add_argument('--vision_dset', action = 'store_true')\n",
    "parser.add_argument('--task', required=True, type=str,choices = ['binary','multiclass','regression'])\n",
    "parser.add_argument('--cont_embeddings', default='MLP', type=str,choices = ['MLP','Noemb','pos_singleMLP'])\n",
    "parser.add_argument('--embedding_size', default=32, type=int)\n",
    "parser.add_argument('--transformer_depth', default=6, type=int)\n",
    "parser.add_argument('--attention_heads', default=8, type=int)\n",
    "parser.add_argument('--attention_dropout', default=0.1, type=float)\n",
    "parser.add_argument('--ff_dropout', default=0.1, type=float)\n",
    "parser.add_argument('--attentiontype', default='colrow', type=str,choices = ['col','colrow','row','justmlp','attn','attnmlp'])\n",
    "\n",
    "parser.add_argument('--optimizer', default='AdamW', type=str,choices = ['AdamW','Adam','SGD'])\n",
    "parser.add_argument('--scheduler', default='cosine', type=str,choices = ['cosine','linear'])\n",
    "\n",
    "parser.add_argument('--lr', default=0.0001, type=float)\n",
    "parser.add_argument('--epochs', default=100, type=int)\n",
    "parser.add_argument('--batchsize', default=256, type=int)\n",
    "parser.add_argument('--savemodelroot', default='./bestmodels', type=str)\n",
    "parser.add_argument('--run_name', default='testrun', type=str)\n",
    "parser.add_argument('--set_seed', default= 1 , type=int)\n",
    "parser.add_argument('--dset_seed', default= 5 , type=int)\n",
    "parser.add_argument('--active_log', action = 'store_true')\n",
    "\n",
    "parser.add_argument('--pretrain', action = 'store_true')\n",
    "parser.add_argument('--pretrain_epochs', default=50, type=int)\n",
    "parser.add_argument('--pt_tasks', default=['contrastive','denoising'], type=str,nargs='*',choices = ['contrastive','contrastive_sim','denoising'])\n",
    "parser.add_argument('--pt_aug', default=[], type=str,nargs='*',choices = ['mixup','cutmix'])\n",
    "parser.add_argument('--pt_aug_lam', default=0.1, type=float)\n",
    "parser.add_argument('--mixup_lam', default=0.3, type=float)\n",
    "\n",
    "parser.add_argument('--train_mask_prob', default=0, type=float)\n",
    "parser.add_argument('--mask_prob', default=0, type=float)\n",
    "\n",
    "parser.add_argument('--ssl_avail_y', default= 0, type=int)\n",
    "parser.add_argument('--pt_projhead_style', default='diff', type=str,choices = ['diff','same','nohead'])\n",
    "parser.add_argument('--nce_temp', default=0.7, type=float)\n",
    "\n",
    "parser.add_argument('--lam0', default=0.5, type=float)\n",
    "parser.add_argument('--lam1', default=10, type=float)\n",
    "parser.add_argument('--lam2', default=1, type=float)\n",
    "parser.add_argument('--lam3', default=10, type=float)\n",
    "parser.add_argument('--final_mlp_style', default='sep', type=str,choices = ['common','sep'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84657a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_config = {\n",
    "        \"vision_dset\": '',\n",
    "        \"task\": 'binary',\n",
    "        \"cont_embeddings\": 'MLP',\n",
    "        \"embedding_size\": 32,\n",
    "        \"transformer_depth\": 6,\n",
    "        \"attention_heads\": 8,\n",
    "        \"attention_dropout\": 0.1,\n",
    "        \"ff_dropout\": 0.1,\n",
    "        \"attentiontype\": 'colrow',\n",
    "    \n",
    "        \"optimizer\": 'Adam',\n",
    "        \"scheduler\": 'cosine',\n",
    "        \n",
    "        \"lr\": 0.0001,\n",
    "        \"epochs\": 100,\n",
    "        \"batchsize\": 256,\n",
    "        \"savemodelroot\": './bestmodels',\n",
    "        \"run_name\": 'testrun',\n",
    "        \"set_seed\": 1,\n",
    "        \"dset_seed\": 5,\n",
    "        \"active_log\": '',\n",
    "    \n",
    "        \"final_mlp_style\": 'sep'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64b47487",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsave_path = os.path.join(os.getcwd(), custom_config[\"savemodelroot\"] , custom_config[\"task\"], custom_config[\"run_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b49d5dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58ef156a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device is cpu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eric0\\AppData\\Local\\Temp\\ipykernel_13768\\3206652255.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[\"Set\"] = np.random.choice([\"train\", \"valid\", \"test\"], p = datasplit, size=(X.shape[0],))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 64\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device is {device}.\")\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "cat_dims, cat_idxs, con_idxs, X_train, y_train, X_valid, y_valid, X_test, y_test, train_mean, train_std = data_prep(train, target_name = 'target', seed = custom_config['set_seed'], task = custom_config['task'], datasplit=[.65, .15, .2])\n",
    "continuous_mean_std = np.array([train_mean,train_std]).astype(np.float32) \n",
    "\n",
    "##### Setting some hyperparams based on inputs and dataset\n",
    "_,nfeat = X_train['data'].shape\n",
    "if nfeat > 100:\n",
    "    custom_config['embedding_size'] = min(8,custom_config['embedding_size'])\n",
    "    custom_config['batchsize'] = min(64, custom_config['batchsize'])\n",
    "if custom_config['attentiontype'] != 'col':\n",
    "    custom_config['transformer_depth'] = 1\n",
    "    custom_config['attention_heads'] = min(4,custom_config['attention_heads'])\n",
    "    custom_config['attention_dropout'] = 0.8\n",
    "    custom_config['embedding_size'] = min(32,custom_config['embedding_size'])\n",
    "    custom_config['ff_dropout'] = 0.8\n",
    "\n",
    "print(nfeat,custom_config['batchsize'])\n",
    "\n",
    "train_ds = DataSetCatCon(X_train, y_train, cat_idxs, 'clf', continuous_mean_std)\n",
    "trainloader = DataLoader(train_ds, batch_size=custom_config['batchsize'], shuffle=True,num_workers=0)\n",
    "\n",
    "valid_ds = DataSetCatCon(X_valid, y_valid, cat_idxs, 'clf', continuous_mean_std)\n",
    "validloader = DataLoader(valid_ds, batch_size=custom_config['batchsize'], shuffle=False,num_workers=0)\n",
    "\n",
    "test_ds = DataSetCatCon(X_test, y_test, cat_idxs, 'clf', continuous_mean_std)\n",
    "testloader = DataLoader(test_ds, batch_size=custom_config['batchsize'], shuffle=False,num_workers=0)\n",
    "\n",
    "if custom_config['task'] == 'regression':\n",
    "    y_dim = 1\n",
    "else:\n",
    "    y_dim = len(np.unique(y_train['data'][:,0]))\n",
    "\n",
    "cat_dims = np.append(np.array([1]),np.array(cat_dims)).astype(int) #Appending 1 for CLS token, this is later used to generate embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eb7dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SAINT(\n",
    "categories = tuple(cat_dims), \n",
    "num_continuous = len(con_idxs),                \n",
    "dim = custom_config['embedding_size'],                           \n",
    "dim_out = 1,                       \n",
    "depth = custom_config['transformer_depth'],                       \n",
    "heads = custom_config['attention_heads'],                         \n",
    "attn_dropout = custom_config['attention_dropout'],             \n",
    "ff_dropout = custom_config['ff_dropout'],                  \n",
    "mlp_hidden_mults = (4, 2),       \n",
    "cont_embeddings = custom_config['cont_embeddings'],\n",
    "attentiontype = custom_config['attentiontype'],\n",
    "final_mlp_style = custom_config['final_mlp_style'],\n",
    "y_dim = y_dim\n",
    ")\n",
    "vision_dset = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85ea821d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAINT(\n",
       "  (norm): LayerNorm((200,), eps=1e-05, elementwise_affine=True)\n",
       "  (simple_MLP): ModuleList(\n",
       "    (0): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (3): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (4): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (5): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (6): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (7): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (8): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (9): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (10): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (11): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (12): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (13): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (14): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (15): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (16): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (17): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (18): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (19): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (20): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (21): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (22): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (23): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (24): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (25): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (26): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (27): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (28): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (29): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (30): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (31): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (32): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (33): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (34): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (35): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (36): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (37): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (38): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (39): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (40): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (41): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (42): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (43): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (44): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (45): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (46): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (47): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (48): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (49): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (50): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (51): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (52): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (53): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (54): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (55): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (56): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (57): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (58): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (59): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (60): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (61): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (62): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (63): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (64): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (65): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (66): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (67): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (68): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (69): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (70): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (71): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (72): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (73): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (74): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (75): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (76): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (77): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (78): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (79): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (80): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (81): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (82): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (83): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (84): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (85): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (86): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (87): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (88): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (89): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (90): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (91): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (92): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (93): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (94): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (95): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (96): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (97): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (98): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (99): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (100): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (101): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (102): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (103): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (104): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (105): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (106): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (107): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (108): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (109): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (110): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (111): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (112): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (113): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (114): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (115): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (116): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (117): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (118): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (119): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (120): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (121): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (122): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (123): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (124): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (125): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (126): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (127): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (128): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (129): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (130): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (131): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (132): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (133): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (134): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (135): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (136): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (137): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (138): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (139): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (140): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (141): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (142): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (143): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (144): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (145): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (146): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (147): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (148): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (149): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (150): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (151): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (152): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (153): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (154): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (155): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (156): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (157): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (158): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (159): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (160): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (161): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (162): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (163): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (164): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (165): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (166): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (167): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (168): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (169): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (170): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (171): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (172): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (173): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (174): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (175): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (176): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (177): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (178): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (179): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (180): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (181): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (182): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (183): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (184): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (185): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (186): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (187): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (188): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (189): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (190): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (191): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (192): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (193): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (194): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (195): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (196): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (197): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (198): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (199): simple_MLP(\n",
       "      (layers): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=100, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=100, out_features=8, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transformer): RowColTransformer(\n",
       "    (embeds): Embedding(1, 8)\n",
       "    (layers): ModuleList(\n",
       "      (0): ModuleList(\n",
       "        (0): PreNorm(\n",
       "          (norm): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=8, out_features=192, bias=False)\n",
       "              (to_out): Linear(in_features=64, out_features=8, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): PreNorm(\n",
       "          (norm): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=8, out_features=64, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=32, out_features=8, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): PreNorm(\n",
       "          (norm): LayerNorm((1608,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): Attention(\n",
       "              (to_qkv): Linear(in_features=1608, out_features=768, bias=False)\n",
       "              (to_out): Linear(in_features=256, out_features=1608, bias=True)\n",
       "              (dropout): Dropout(p=0.8, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): PreNorm(\n",
       "          (norm): LayerNorm((1608,), eps=1e-05, elementwise_affine=True)\n",
       "          (fn): Residual(\n",
       "            (fn): FeedForward(\n",
       "              (net): Sequential(\n",
       "                (0): Linear(in_features=1608, out_features=12864, bias=True)\n",
       "                (1): GEGLU()\n",
       "                (2): Dropout(p=0.8, inplace=False)\n",
       "                (3): Linear(in_features=6432, out_features=1608, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mask_embed): Embedding(201, 8)\n",
       "  )\n",
       "  (mlp): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=1608, out_features=804, bias=True)\n",
       "      (1): Linear(in_features=804, out_features=402, bias=True)\n",
       "      (2): Linear(in_features=402, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (embeds): Embedding(1, 8)\n",
       "  (mask_embeds_cat): Embedding(2, 8)\n",
       "  (mask_embeds_cont): Embedding(400, 8)\n",
       "  (single_mask): Embedding(2, 8)\n",
       "  (pos_encodings): Embedding(201, 8)\n",
       "  (mlp1): sep_MLP(\n",
       "    (layers): ModuleList(\n",
       "      (0): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlp2): sep_MLP(\n",
       "    (layers): ModuleList(\n",
       "      (0): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (4): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (5): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (6): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (7): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (8): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (9): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (10): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (11): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (12): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (13): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (14): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (15): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (16): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (17): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (18): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (19): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (20): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (21): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (22): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (23): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (24): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (25): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (26): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (27): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (28): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (29): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (30): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (31): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (32): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (33): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (34): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (35): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (36): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (37): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (38): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (39): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (40): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (41): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (42): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (43): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (44): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (45): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (46): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (47): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (48): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (49): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (50): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (51): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (52): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (53): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (54): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (55): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (56): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (57): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (58): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (59): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (60): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (61): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (62): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (63): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (64): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (65): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (66): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (67): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (68): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (69): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (70): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (71): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (72): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (73): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (74): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (75): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (76): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (77): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (78): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (79): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (80): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (81): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (82): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (83): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (84): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (85): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (86): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (87): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (88): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (89): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (90): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (91): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (92): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (93): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (94): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (95): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (96): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (97): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (98): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (99): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (100): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (101): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (102): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (103): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (104): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (105): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (106): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (107): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (108): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (109): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (110): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (111): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (112): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (113): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (114): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (115): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (116): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (117): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (118): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (119): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (120): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (121): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (122): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (123): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (124): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (125): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (126): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (127): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (128): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (129): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (130): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (131): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (132): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (133): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (134): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (135): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (136): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (137): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (138): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (139): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (140): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (141): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (142): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (143): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (144): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (145): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (146): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (147): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (148): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (149): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (150): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (151): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (152): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (153): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (154): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (155): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (156): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (157): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (158): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (159): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (160): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (161): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (162): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (163): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (164): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (165): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (166): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (167): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (168): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (169): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (170): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (171): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (172): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (173): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (174): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (175): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (176): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (177): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (178): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (179): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (180): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (181): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (182): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (183): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (184): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (185): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (186): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (187): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (188): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (189): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (190): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (191): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (192): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (193): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (194): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (195): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (196): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (197): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (198): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (199): simple_MLP(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=40, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=40, out_features=1, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlpfory): simple_MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=8, out_features=1000, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1000, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (pt_mlp): simple_MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=1608, out_features=1929, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1929, out_features=804, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (pt_mlp2): simple_MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=1608, out_features=1929, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=1929, out_features=804, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if y_dim == 2 and custom_config['task'] == 'binary':\n",
    "    # opt.task = 'binary'\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "elif y_dim > 2 and custom_config['task'] == 'multiclass':\n",
    "    # opt.task = 'multiclass'\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "elif custom_config['task'] == 'regression':\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "else:\n",
    "    raise'case not written yet'\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "225f9a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training begins now.\n"
     ]
    }
   ],
   "source": [
    "#if custom_config['pretrain']: \n",
    "#    model = SAINT_pretrain(model, cat_idxs,X_train,y_train, continuous_mean_std, opt,device)\n",
    "\n",
    "## Choosing the optimizer\n",
    "\n",
    "if custom_config['optimizer'] == 'SGD':\n",
    "    optimizer = optim.SGD(model.parameters(), lr=opt.lr,\n",
    "                          momentum=0.9, weight_decay=5e-4)\n",
    "    from utils import get_scheduler\n",
    "    scheduler = get_scheduler(opt, optimizer)\n",
    "elif custom_config['optimizer'] == 'Adam':\n",
    "    optimizer = optim.Adam(model.parameters(),lr=custom_config['lr'])\n",
    "elif custom_config['optimizer'] == 'AdamW':\n",
    "    optimizer = optim.AdamW(model.parameters(),lr=opt.lr)\n",
    "\n",
    "best_valid_auroc = 0\n",
    "best_valid_accuracy = 0\n",
    "best_test_auroc = 0\n",
    "best_test_accuracy = 0\n",
    "best_valid_rmse = 100000\n",
    "print('Training begins now.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6d508b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "example_batch = next(dataiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9bb198",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(custom_config['epochs']):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        # x_categ is the the categorical data, x_cont has continuous data, y_gts has ground truth ys. cat_mask is an array of ones same shape as x_categ and an additional column(corresponding to CLS token) set to 0s. con_mask is an array of ones same shape as x_cont. \n",
    "        x_categ, x_cont, y_gts, cat_mask, con_mask = data[0].to(device), data[1].to(device),data[2].to(device),data[3].to(device),data[4].to(device)\n",
    "\n",
    "        # We are converting the data to embeddings in the next step\n",
    "        _ , x_categ_enc, x_cont_enc = embed_data_mask(x_categ, x_cont, cat_mask, con_mask,model,vision_dset)           \n",
    "        reps = model.transformer(x_categ_enc, x_cont_enc)\n",
    "        # select only the representations corresponding to CLS token and apply mlp on it in the next step to get the predictions.\n",
    "        y_reps = reps[:,0,:]\n",
    "        \n",
    "        y_outs = model.mlpfory(y_reps)\n",
    "        if custom_config['task'] == 'regression':\n",
    "            loss = criterion(y_outs,y_gts) \n",
    "        else:\n",
    "            loss = criterion(y_outs,y_gts.squeeze()) \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(i +'번째' +running_loss)\n",
    "    if epoch%5==0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                if custom_config['task'] in ['binary','multiclass']:\n",
    "                    accuracy, auroc = classification_scores(model, validloader, device, custom_config['task'], vision_dset)\n",
    "                    test_accuracy, test_auroc = classification_scores(model, testloader, device, custom_config['task'],vision_dset)\n",
    "\n",
    "                    print('[EPOCH %d] VALID ACCURACY: %.3f, VALID AUROC: %.3f' %\n",
    "                        (epoch + 1, accuracy,auroc ))\n",
    "                    print('[EPOCH %d] TEST ACCURACY: %.3f, TEST AUROC: %.3f' %\n",
    "                        (epoch + 1, test_accuracy,test_auroc ))\n",
    "                    \n",
    "                    if custom_config['task'] =='multiclass':\n",
    "                        if accuracy > best_valid_accuracy:\n",
    "                            best_valid_accuracy = accuracy\n",
    "                            best_test_auroc = test_auroc\n",
    "                            best_test_accuracy = test_accuracy\n",
    "                            torch.save(model.state_dict(),'%s/bestmodel.pth' % (modelsave_path))\n",
    "                    else:\n",
    "                        if accuracy > best_valid_accuracy:\n",
    "                            best_valid_accuracy = accuracy\n",
    "                        # if auroc > best_valid_auroc:\n",
    "                        #     best_valid_auroc = auroc\n",
    "                            best_test_auroc = test_auroc\n",
    "                            best_test_accuracy = test_accuracy               \n",
    "                            torch.save(model.state_dict(),'%s/bestmodel.pth' % (modelsave_path))\n",
    "\n",
    "                else:\n",
    "                    valid_rmse = mean_sq_error(model, validloader, device,vision_dset)    \n",
    "                    test_rmse = mean_sq_error(model, testloader, device,vision_dset)  \n",
    "                    print('[EPOCH %d] VALID RMSE: %.3f' %\n",
    "                        (epoch + 1, valid_rmse ))\n",
    "                    print('[EPOCH %d] TEST RMSE: %.3f' %\n",
    "                        (epoch + 1, test_rmse ))\n",
    "                    if opt.active_log:\n",
    "                        wandb.log({'valid_rmse': valid_rmse ,'test_rmse': test_rmse })     \n",
    "                    if valid_rmse < best_valid_rmse:\n",
    "                        best_valid_rmse = valid_rmse\n",
    "                        best_test_rmse = test_rmse\n",
    "                        torch.save(model.state_dict(),'%s/bestmodel.pth' % (modelsave_path))\n",
    "            model.train()\n",
    "                \n",
    "\n",
    "\n",
    "total_parameters = count_parameters(model)\n",
    "print('TOTAL NUMBER OF PARAMS: %d' %(total_parameters))\n",
    "if custom_config['task'] =='binary':\n",
    "    print('AUROC on best model:  %.3f' %(best_test_auroc))\n",
    "elif custom_config['task'] =='multiclass':\n",
    "    print('Accuracy on best model:  %.3f' %(best_test_accuracy))\n",
    "else:\n",
    "    print('RMSE on best model:  %.3f' %(best_test_rmse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
