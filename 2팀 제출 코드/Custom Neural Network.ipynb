{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8243ce36",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42da1f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; np.random.seed(0)\n",
    "import tensorflow as tf; tf.random.set_seed(seed=0)\n",
    "import pandas as pd\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing import text, sequence\n",
    "import numpy as np\n",
    "from keras.constraints import max_norm\n",
    "from keras.callbacks import *\n",
    "from keras.initializers import Orthogonal\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LambdaCallback, Callback, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pickle\n",
    "import gc; gc.enable()\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import string\n",
    "from scipy.stats import boxcox\n",
    "import re\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, activations\n",
    "from keras.metrics import *\n",
    "from datetime import datetime\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from ipywidgets import IntProgress\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import warnings; warnings.filterwarnings('ignore') \n",
    "from sklearn.metrics import accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944e9681",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1050bdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./train/train.csv')\n",
    "train.drop(['ID_code'], axis=1, inplace=True)\n",
    "test = pd.read_csv('./test/test.csv')\n",
    "test.drop(['ID_code'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2daa8923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15.4140</td>\n",
       "      <td>-2.1016</td>\n",
       "      <td>10.4773</td>\n",
       "      <td>4.8941</td>\n",
       "      <td>12.6506</td>\n",
       "      <td>-3.7205</td>\n",
       "      <td>5.1426</td>\n",
       "      <td>17.7048</td>\n",
       "      <td>4.2444</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.8810</td>\n",
       "      <td>8.1647</td>\n",
       "      <td>1.0927</td>\n",
       "      <td>2.1215</td>\n",
       "      <td>17.6536</td>\n",
       "      <td>3.2253</td>\n",
       "      <td>-2.1234</td>\n",
       "      <td>8.9516</td>\n",
       "      <td>13.3485</td>\n",
       "      <td>-16.0178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>12.3576</td>\n",
       "      <td>-8.1666</td>\n",
       "      <td>11.7785</td>\n",
       "      <td>2.8869</td>\n",
       "      <td>12.3183</td>\n",
       "      <td>-6.9847</td>\n",
       "      <td>4.2671</td>\n",
       "      <td>9.6710</td>\n",
       "      <td>3.0662</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>8.1569</td>\n",
       "      <td>-1.0753</td>\n",
       "      <td>5.4679</td>\n",
       "      <td>23.6376</td>\n",
       "      <td>-0.5022</td>\n",
       "      <td>9.2414</td>\n",
       "      <td>8.2427</td>\n",
       "      <td>10.7546</td>\n",
       "      <td>-3.4394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>9.4142</td>\n",
       "      <td>-8.6132</td>\n",
       "      <td>7.2196</td>\n",
       "      <td>3.2496</td>\n",
       "      <td>10.6550</td>\n",
       "      <td>-3.3245</td>\n",
       "      <td>5.1010</td>\n",
       "      <td>18.5389</td>\n",
       "      <td>1.8721</td>\n",
       "      <td>...</td>\n",
       "      <td>8.1638</td>\n",
       "      <td>9.2399</td>\n",
       "      <td>1.0160</td>\n",
       "      <td>7.4548</td>\n",
       "      <td>17.0933</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>-4.0455</td>\n",
       "      <td>9.4586</td>\n",
       "      <td>17.8789</td>\n",
       "      <td>-13.9784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>13.0647</td>\n",
       "      <td>-0.7917</td>\n",
       "      <td>13.0270</td>\n",
       "      <td>8.7865</td>\n",
       "      <td>10.2252</td>\n",
       "      <td>-2.9311</td>\n",
       "      <td>6.7299</td>\n",
       "      <td>11.8682</td>\n",
       "      <td>-2.1274</td>\n",
       "      <td>...</td>\n",
       "      <td>9.3914</td>\n",
       "      <td>7.5576</td>\n",
       "      <td>0.4784</td>\n",
       "      <td>1.2138</td>\n",
       "      <td>19.0498</td>\n",
       "      <td>-1.5634</td>\n",
       "      <td>7.3092</td>\n",
       "      <td>8.4344</td>\n",
       "      <td>18.1104</td>\n",
       "      <td>-7.7668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>9.5222</td>\n",
       "      <td>-0.2727</td>\n",
       "      <td>8.2173</td>\n",
       "      <td>8.4071</td>\n",
       "      <td>12.7732</td>\n",
       "      <td>-10.3113</td>\n",
       "      <td>4.7486</td>\n",
       "      <td>13.7810</td>\n",
       "      <td>-1.1586</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4802</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.9973</td>\n",
       "      <td>1.9370</td>\n",
       "      <td>24.4786</td>\n",
       "      <td>-2.0294</td>\n",
       "      <td>-0.5454</td>\n",
       "      <td>8.7461</td>\n",
       "      <td>21.3832</td>\n",
       "      <td>14.1786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159995</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0801</td>\n",
       "      <td>-2.5523</td>\n",
       "      <td>10.6587</td>\n",
       "      <td>10.6660</td>\n",
       "      <td>8.7552</td>\n",
       "      <td>-10.8144</td>\n",
       "      <td>5.2019</td>\n",
       "      <td>21.1479</td>\n",
       "      <td>0.4870</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9773</td>\n",
       "      <td>7.5440</td>\n",
       "      <td>0.8520</td>\n",
       "      <td>4.9402</td>\n",
       "      <td>19.0033</td>\n",
       "      <td>1.5157</td>\n",
       "      <td>-9.3063</td>\n",
       "      <td>9.0586</td>\n",
       "      <td>14.9677</td>\n",
       "      <td>-11.2478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159996</th>\n",
       "      <td>0</td>\n",
       "      <td>11.8371</td>\n",
       "      <td>-4.9598</td>\n",
       "      <td>12.9172</td>\n",
       "      <td>9.3759</td>\n",
       "      <td>13.0622</td>\n",
       "      <td>2.6849</td>\n",
       "      <td>5.2963</td>\n",
       "      <td>19.8298</td>\n",
       "      <td>3.6545</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3344</td>\n",
       "      <td>13.5478</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>-1.5778</td>\n",
       "      <td>17.3154</td>\n",
       "      <td>-0.9673</td>\n",
       "      <td>4.9180</td>\n",
       "      <td>8.8015</td>\n",
       "      <td>13.2019</td>\n",
       "      <td>-21.5102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159997</th>\n",
       "      <td>0</td>\n",
       "      <td>11.3368</td>\n",
       "      <td>1.2790</td>\n",
       "      <td>14.1568</td>\n",
       "      <td>11.9850</td>\n",
       "      <td>11.4859</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>5.9112</td>\n",
       "      <td>19.7031</td>\n",
       "      <td>2.4183</td>\n",
       "      <td>...</td>\n",
       "      <td>5.7440</td>\n",
       "      <td>11.3343</td>\n",
       "      <td>2.8999</td>\n",
       "      <td>4.8399</td>\n",
       "      <td>14.0429</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>-0.0909</td>\n",
       "      <td>6.7786</td>\n",
       "      <td>13.0894</td>\n",
       "      <td>-0.6329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159998</th>\n",
       "      <td>0</td>\n",
       "      <td>3.4660</td>\n",
       "      <td>-0.2570</td>\n",
       "      <td>4.3530</td>\n",
       "      <td>7.2045</td>\n",
       "      <td>11.4988</td>\n",
       "      <td>-7.0838</td>\n",
       "      <td>5.5081</td>\n",
       "      <td>13.7160</td>\n",
       "      <td>-1.0089</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3471</td>\n",
       "      <td>2.6189</td>\n",
       "      <td>4.6409</td>\n",
       "      <td>9.0566</td>\n",
       "      <td>15.5558</td>\n",
       "      <td>-0.0071</td>\n",
       "      <td>1.0802</td>\n",
       "      <td>9.6420</td>\n",
       "      <td>14.3480</td>\n",
       "      <td>4.5444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159999</th>\n",
       "      <td>0</td>\n",
       "      <td>8.5913</td>\n",
       "      <td>-0.8183</td>\n",
       "      <td>11.0295</td>\n",
       "      <td>5.9502</td>\n",
       "      <td>12.9875</td>\n",
       "      <td>-7.8987</td>\n",
       "      <td>5.9785</td>\n",
       "      <td>17.9756</td>\n",
       "      <td>-6.4178</td>\n",
       "      <td>...</td>\n",
       "      <td>9.6247</td>\n",
       "      <td>6.1803</td>\n",
       "      <td>1.1074</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>21.2442</td>\n",
       "      <td>1.5998</td>\n",
       "      <td>6.1462</td>\n",
       "      <td>10.2161</td>\n",
       "      <td>19.4946</td>\n",
       "      <td>13.3942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160000 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target    var_0   var_1    var_2    var_3    var_4    var_5   var_6  \\\n",
       "0            0  15.4140 -2.1016  10.4773   4.8941  12.6506  -3.7205  5.1426   \n",
       "1            0  12.3576 -8.1666  11.7785   2.8869  12.3183  -6.9847  4.2671   \n",
       "2            0   9.4142 -8.6132   7.2196   3.2496  10.6550  -3.3245  5.1010   \n",
       "3            0  13.0647 -0.7917  13.0270   8.7865  10.2252  -2.9311  6.7299   \n",
       "4            0   9.5222 -0.2727   8.2173   8.4071  12.7732 -10.3113  4.7486   \n",
       "...        ...      ...     ...      ...      ...      ...      ...     ...   \n",
       "159995       0   8.0801 -2.5523  10.6587  10.6660   8.7552 -10.8144  5.2019   \n",
       "159996       0  11.8371 -4.9598  12.9172   9.3759  13.0622   2.6849  5.2963   \n",
       "159997       0  11.3368  1.2790  14.1568  11.9850  11.4859   0.2191  5.9112   \n",
       "159998       0   3.4660 -0.2570   4.3530   7.2045  11.4988  -7.0838  5.5081   \n",
       "159999       0   8.5913 -0.8183  11.0295   5.9502  12.9875  -7.8987  5.9785   \n",
       "\n",
       "          var_7   var_8  ...  var_190  var_191  var_192  var_193  var_194  \\\n",
       "0       17.7048  4.2444  ...  -2.8810   8.1647   1.0927   2.1215  17.6536   \n",
       "1        9.6710  3.0662  ...   0.2397   8.1569  -1.0753   5.4679  23.6376   \n",
       "2       18.5389  1.8721  ...   8.1638   9.2399   1.0160   7.4548  17.0933   \n",
       "3       11.8682 -2.1274  ...   9.3914   7.5576   0.4784   1.2138  19.0498   \n",
       "4       13.7810 -1.1586  ...   8.4802   0.9951   3.9973   1.9370  24.4786   \n",
       "...         ...     ...  ...      ...      ...      ...      ...      ...   \n",
       "159995  21.1479  0.4870  ...   4.9773   7.5440   0.8520   4.9402  19.0033   \n",
       "159996  19.8298  3.6545  ...   2.3344  13.5478   3.1656  -1.5778  17.3154   \n",
       "159997  19.7031  2.4183  ...   5.7440  11.3343   2.8999   4.8399  14.0429   \n",
       "159998  13.7160 -1.0089  ...   2.3471   2.6189   4.6409   9.0566  15.5558   \n",
       "159999  17.9756 -6.4178  ...   9.6247   6.1803   1.1074   0.8214  21.2442   \n",
       "\n",
       "        var_195  var_196  var_197  var_198  var_199  \n",
       "0        3.2253  -2.1234   8.9516  13.3485 -16.0178  \n",
       "1       -0.5022   9.2414   8.2427  10.7546  -3.4394  \n",
       "2        0.0715  -4.0455   9.4586  17.8789 -13.9784  \n",
       "3       -1.5634   7.3092   8.4344  18.1104  -7.7668  \n",
       "4       -2.0294  -0.5454   8.7461  21.3832  14.1786  \n",
       "...         ...      ...      ...      ...      ...  \n",
       "159995   1.5157  -9.3063   9.0586  14.9677 -11.2478  \n",
       "159996  -0.9673   4.9180   8.8015  13.2019 -21.5102  \n",
       "159997   0.5310  -0.0909   6.7786  13.0894  -0.6329  \n",
       "159998  -0.0071   1.0802   9.6420  14.3480   4.5444  \n",
       "159999   1.5998   6.1462  10.2161  19.4946  13.3942  \n",
       "\n",
       "[160000 rows x 201 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0386234",
   "metadata": {},
   "source": [
    "## Processing Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fcbfce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_freq_feature(df1,df2,df3_base,feat):\n",
    "    vc=df1[feat].append(df3_base[feat]).value_counts()\n",
    "    df1[feat +\"_freq\"]= df1[feat].map(vc)\n",
    "    df2[feat+\"_freq\"]= df2[feat].map(vc)\n",
    "    \n",
    "def load_data(train, test, feature_cols):\n",
    "    train_df = train[feature_cols].copy()\n",
    "    test_df = test[feature_cols].copy()\n",
    "    real_test_df = test[feature_cols].copy()\n",
    "\n",
    "    unique_samples = []\n",
    "    unique_count = np.zeros_like(test_df)\n",
    "    for feature in range(test_df.shape[1]):\n",
    "        _, index_, count_ = np.unique(test_df.values[:, feature], return_counts=True, return_index=True)\n",
    "        unique_count[index_[count_ == 1], feature] += 1\n",
    "\n",
    "    # Samples which have unique values are real the others are fake\n",
    "    real_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) > 0)[:, 0]\n",
    "    synthetic_samples_indexes = np.argwhere(np.sum(unique_count, axis=1) == 0)[:, 0]\n",
    "    real_test_df=real_test_df.iloc[real_samples_indexes]\n",
    "    \n",
    "    for col in feature_cols:\n",
    "        transform_freq_feature(train_df,test_df,real_test_df,col)\n",
    "        \n",
    "    for f in feature_cols: # normalzie\n",
    "        vals = train_df[f].append(test_df.loc[real_samples_indexes,f]).values\n",
    "        m, s = vals.mean(), vals.std()\n",
    "        train_df[f] = (train_df[f]-m)/s\n",
    "        test_df[f] = (test_df[f]-m)/s\n",
    "    \n",
    "    return train_df, test_df, real_samples_indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91c718e",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "580d77ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # share components\n",
    "    inputs = Input(shape=(200,2))\n",
    "    \n",
    "    main = inputs\n",
    "    main = Dense(64, activation='relu')(main)\n",
    "    main = Dense(32, activation='relu')(main)\n",
    "    main = Flatten()(main)\n",
    "    \n",
    "    out = Dense(1, activation = 'sigmoid')(main) # 1 class to be classified\n",
    "\n",
    "    model = Model(inputs, out)\n",
    "    model.regularizers = [regularizers.l2(0.0001)]\n",
    "    \n",
    "    model.compile(optimizer = Adam(lr=0.001, clipnorm=1.), loss=\"binary_crossentropy\")\n",
    "    \n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3364244",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cda5d1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class auc_score_monitor(Callback):\n",
    "    def __init__(self, val_data, val_target, checkpoint_file, min_lr =1e-5, reduce_lr_patience=2, early_stop_patience=4, factor=0.1):\n",
    "        self.val_data = val_data\n",
    "        self.val_target = val_target\n",
    "        self.checkpoint_file = checkpoint_file\n",
    "        self.reduce_lr_patience = reduce_lr_patience\n",
    "        self.early_stop_patience = early_stop_patience\n",
    "        self.best_val_score = 0\n",
    "        self.epoch_num = 0\n",
    "        self.factor = factor\n",
    "        self.unimproved_lr_counter = 0\n",
    "        self.unimproved_stop_counter = 0\n",
    "        self.min_lr = min_lr\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_scores = []\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        val_pred = self.model.predict(self.val_data).reshape((-1,))\n",
    "        val_score = roc_auc_score(self.val_target, val_pred)\n",
    "        # clip pred\n",
    "        self.val_scores.append(val_score)\n",
    "        \n",
    "        #print(self.val_target, '\\n', val_pred)\n",
    "        print('Epoch {} val_score: {:.5f}'.format(self.epoch_num, val_score))\n",
    "        self.epoch_num += 1\n",
    "        \n",
    "        if val_score > self.best_val_score:\n",
    "            print ('Val Score improve from {:5f} to {:5f}'.format(self.best_val_score, val_score))\n",
    "            self.best_val_score = val_score\n",
    "            self.unimproved_lr_counter = 0\n",
    "            self.unimproved_stop_counter = 0\n",
    "            if self.checkpoint_file is not None:\n",
    "                print('Saving file to', self.checkpoint_file)\n",
    "                self.model.save_weights(self.checkpoint_file)\n",
    "        else:\n",
    "            if val_score<self.best_val_score:\n",
    "                print('no improve from {:.5f}'.format(self.best_val_score))\n",
    "                self.unimproved_lr_counter += 1\n",
    "                self.unimproved_stop_counter += 1\n",
    "            \n",
    "        if self.reduce_lr_patience is not None and self.unimproved_lr_counter >= self.reduce_lr_patience:\n",
    "            current_lr = K.eval(self.model.optimizer.lr)\n",
    "            if current_lr > self.min_lr:\n",
    "                print('Reduce LR from {:.6f} to {:.6f}'.format(current_lr, current_lr*self.factor))\n",
    "                K.set_value(self.model.optimizer.lr, current_lr*self.factor)\n",
    "                #self.model.load_weights(self.checkpoint_file)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            self.unimproved_lr_counter = 0\n",
    "            \n",
    "        if self.early_stop_patience is not None and self.unimproved_stop_counter >= self.early_stop_patience:\n",
    "            print('Early Stop Criteria Meet')\n",
    "            self.model.stop_training = True\n",
    "                \n",
    "        return\n",
    "\n",
    "def special_reshape(vals):\n",
    "    return np.vstack([v.reshape((2,-1)).T.reshape((1, -1, 2)) for v in vals])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31106761",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4df40d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence): ##pytorch에서 Dataloader의 역할을 하는 함수\n",
    "    def __init__(self, X, y, batch_size=32, positive_rate=1., negative_rate=1.,\n",
    "                 pl_data=None, pl_soft_label=None, pl_sample_rate=1.):\n",
    "        #'Initialization'\n",
    "        self.batch_size = batch_size\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.positive_rate = positive_rate\n",
    "        self.negative_rate = negative_rate \n",
    "        self.pl_data = pl_data\n",
    "        self.pl_soft_label = pl_soft_label\n",
    "        self.pl_sample_rate = pl_sample_rate\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        #'Denotes the number of batches per epoch'\n",
    "        return int(np.ceil(len(self.resampled_y) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        start = index*self.batch_size\n",
    "        end = min((index+1)*self.batch_size, len(self.resampled_y))\n",
    "        indexes = np.arange(len(self.resampled_y))[start: end]\n",
    "\n",
    "        # Generate data\n",
    "        return self.resampled_X[indexes,:,:], self.resampled_y[indexes]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Dataaugmentation + shuffle\n",
    "        feat_len = 200\n",
    "        \n",
    "        if self.pl_data is not None:\n",
    "            pl_idx = np.random.choice(np.arange(self.pl_data.shape[0]), \n",
    "                                      size=int(self.pl_data.shape[0]*self.pl_sample_rate), \n",
    "                                      replace=False)\n",
    "            \n",
    "            pl_y = self.pl_soft_label[pl_idx].copy()\n",
    "            pl_x = self.pl_data[pl_idx,:].copy()\n",
    "            \n",
    "            pl_y_rank = pd.Series(pl_y).rank(ascending=False)\n",
    "            filt = pl_y_rank<=int(len(pl_y)*.1) # mark top 10 % rank data as 1\n",
    "            pl_y[filt] = 1.\n",
    "            pl_y[~filt] = 0.\n",
    "            \n",
    "            X_p = np.concatenate([self.X[self.y==1], pl_x[pl_y==1]], axis=0)\n",
    "            X_n = np.concatenate([self.X[self.y==0], pl_x[pl_y==0]], axis=0)\n",
    "        else:    \n",
    "            X_p = self.X[self.y==1]\n",
    "            X_n = self.X[self.y==0]\n",
    "        \n",
    "        pos_size = int(self.positive_rate*X_p.shape[0])\n",
    "        X_p_new = np.zeros((pos_size, X_p.shape[1])).astype(np.float32)\n",
    "        neg_size = int(self.negative_rate*X_n.shape[0])\n",
    "        X_n_new = np.zeros((neg_size, X_n.shape[1])).astype(np.float32)\n",
    "        \n",
    "        for f in range(feat_len):\n",
    "            pos_idx = np.random.choice(np.arange(X_p.shape[0]), size=pos_size, replace=True)\n",
    "            X_p_new[:, f] = X_p[pos_idx,f]\n",
    "            X_p_new[:, f+feat_len] = X_p[pos_idx,f+feat_len]\n",
    "            \n",
    "            neg_idx = np.random.choice(np.arange(X_n.shape[0]), size=neg_size, replace=True)\n",
    "            X_n_new[:, f] = X_n[neg_idx,f]\n",
    "            X_n_new[:, f+feat_len] = X_n[neg_idx,f+feat_len]\n",
    "            \n",
    "        self.resampled_X = np.vstack([X_p_new, X_n_new])\n",
    "        self.resampled_y = np.array([1]*pos_size+[0]*neg_size)\n",
    "        \n",
    "        seq = np.random.choice(np.arange(len(self.resampled_y)), size=len(self.resampled_y), replace=False)\n",
    "        self.resampled_X = special_reshape(self.resampled_X[seq, :])\n",
    "        self.resampled_y = self.resampled_y[seq]\n",
    "        #print(self.resampled_X.shape, self.resampled_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5721715",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5215b949",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27008/1622911403.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mte_real_samples_indexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# configs for NN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27008/1963078239.py\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(train, test, feature_cols)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeature_cols\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mtransform_freq_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreal_test_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeature_cols\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# normalzie\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27008/1963078239.py\u001b[0m in \u001b[0;36mtransform_freq_feature\u001b[1;34m(df1, df2, df3_base, feat)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtransform_freq_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf3_base\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mvc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf3_base\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeat\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m\"_freq\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_freq\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   4159\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4160\u001b[0m         \"\"\"\n\u001b[1;32m-> 4161\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4162\u001b[0m         return self._constructor(new_values, index=self.index).__finalize__(\n\u001b[0;32m   4163\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"map\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_map_values\u001b[1;34m(self, mapper, na_action)\u001b[0m\n\u001b[0;32m    840\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 842\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    843\u001b[0m             \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake_nd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3484\u001b[0m             )\n\u001b[0;32m   3485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3486\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3488\u001b[0m     def _get_indexer(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_get_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3510\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_nearest_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3511\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3512\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_engine_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3514\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mensure_platform_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_indexer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Float64HashTable.lookup\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order, like)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;33m@\u001b[0m\u001b[0mset_array_function_like_doc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mset_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'numpy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    special_cols = [col for col in train.columns if train[col].dtype != np.float64] # 범주형 변수 불러오기\n",
    "    feature_cols = [col for col in train.columns if col not in special_cols]\n",
    "    target = train.target.values\n",
    "    \n",
    "    train_df, test_df, te_real_samples_indexes = load_data(train, test, feature_cols)\n",
    "    \n",
    "    # configs for NN\n",
    "    seed = 0\n",
    "    train_epochs = 50\n",
    "    batch_size=32\n",
    "    cpu_count=4  \n",
    "    n_classses = 1\n",
    "    fold_num = 4\n",
    "    model_prefix = 'nn-aug-v5' #'rnn-with-marcus-features-v4'\n",
    "    bags = 10\n",
    "    pseudo_label = False\n",
    "    pseudo_label_sample_rate = 0.8\n",
    "    \n",
    "    # training models with several bags\n",
    "    for b in range(bags):\n",
    "        fold = 0  \n",
    "        \n",
    "        for tr_ix, val_ix in KFold(fold_num, shuffle=True, random_state=seed).split(target, target):  \n",
    "            fold += 1\n",
    "\n",
    "            print(\"fold = {}, bag = {}\".format(fold, b))\n",
    "            \n",
    "            tr = train_df.values[tr_ix,:]\n",
    "            tr_y = target[tr_ix]\n",
    "            \n",
    "            val = special_reshape(train_df.values[val_ix,:])\n",
    "            val_y = target[val_ix]\n",
    "\n",
    "            model = build_model()\n",
    "            file_path = \"./{}_fold_{}_bag_{}.hdf5\".format(model_prefix, fold, b)\n",
    "\n",
    "            lrs = [0.001]*7+[0.0001]*10+[0.00001]*5\n",
    "            lr_schd = LearningRateScheduler(lambda ep: lrs[ep], verbose=1)\n",
    "            wmlog_loss_monitor = auc_score_monitor(val, val_y, \n",
    "                                                   checkpoint_file=None, reduce_lr_patience=None, early_stop_patience=None, \n",
    "                                                   factor=None) # calculate weighted m log loss per epoch\n",
    "\n",
    "            training_generator = DataGenerator(tr, tr_y, batch_size=batch_size, positive_rate=2., negative_rate=1.)\n",
    "            ## DataGenerator는 torch에서 Dataloader랑 같은 역할을 함\n",
    "            \n",
    "            #fit_generator는 torch에서 epoch 돌리는 과정과 같은 역할을 함\n",
    "            history = model.fit_generator(generator=training_generator,\n",
    "                                          validation_data=(val, val_y),\n",
    "                                          use_multiprocessing=False,\n",
    "                                          workers=1, \n",
    "                                          epochs=len(lrs),\n",
    "                                          verbose = 0)\n",
    "            model.save_weights(file_path)\n",
    "            del training_generator; gc.collect()\n",
    "            K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee7daff",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9652cbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.92358\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.91928\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.90829\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.92110\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.92358\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.91928\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.90829\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.92110\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.92358\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.91928\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.90829\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.92110\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.92358\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.91928\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.90829\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.92110\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.92358\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.91928\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.90829\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.92110\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.92358\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.91928\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.90829\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.92110\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.92358\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.91928\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.90829\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.92110\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.92358\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.91928\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.90829\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.92110\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.92358\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.91928\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.90829\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.92110\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.92358\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.91928\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.90829\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "val acc = 0.92110\n",
      "1250/1250 [==============================] - 2s 1ms/step\n",
      "CV Mean = 0.91806, Std = 0.00584, Overall AUC = 0.91816\n"
     ]
    }
   ],
   "source": [
    "# generate oof + submission\n",
    "train_oof = np.zeros((train.shape[0],))\n",
    "test_oof = np.zeros((test.shape[0],))\n",
    "\n",
    "train_aucs = []\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "for b in range(bags):\n",
    "    fold=0\n",
    "    for tr_ix, val_ix in KFold(fold_num, shuffle=True, random_state=seed).split(target, target):    \n",
    "        fold += 1\n",
    "        val = special_reshape(train_df.values[val_ix,:])\n",
    "        val_y = target[val_ix]\n",
    "\n",
    "        file_path = \"./{}_fold_{}_bag_{}.hdf5\".format(model_prefix, fold, bag)\n",
    "\n",
    "        # Predict val + test oofs\n",
    "        model.load_weights(file_path) # load weight with best validation score\n",
    "\n",
    "        pred = model.predict(val, batch_size=batch_size).reshape((len(val_ix),))\n",
    "        train_oof[val_ix] += pred\n",
    "        val_auc = roc_auc_score(target[val_ix], pred)\n",
    "        train_aucs.append(val_auc)\n",
    "        print('val acc = {:.5f}'.format(val_auc))\n",
    "\n",
    "        test_oof += model.predict(special_reshape(test_df.values), batch_size=batch_size).reshape((test.shape[0],))/fold_num\n",
    "\n",
    "train_oof /= bags\n",
    "test_oof /= bags\n",
    "K.clear_session()\n",
    "\n",
    "full_auc = roc_auc_score(target, train_oof)\n",
    "print('CV Mean = {:.5f}, Std = {:.5f}, Overall AUC = {:.5f}'.format(np.mean(train_aucs), np.std(train_aucs), full_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746a13e5",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "220e9b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('./test/test.csv') ## 제출용 ID_code를 빌려오는 용도\n",
    "pd.to_pickle(train_oof, \"./{}_fold_{}_seed_{}_oof_train\".format(model_prefix, fold_num, seed))\n",
    "pd.to_pickle(test_oof, \"./{}_fold_{}_seed_{}_oof_test\".format(model_prefix, fold_num, seed))\n",
    "sub = pd.DataFrame({\"ID_code\": test.ID_code.values})\n",
    "sub[\"target\"] = test_oof\n",
    "sub.to_csv('./' + model_prefix + '_' + str(full_auc).replace('.', '_') + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bc19898",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[\"target\"] = np.where((sub['target']>0.5), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9134ea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('./' + model_prefix + '_' + str(full_auc).replace('.', '_') + \".csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
